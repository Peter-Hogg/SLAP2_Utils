{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad808b7",
   "metadata": {},
   "source": [
    "# SLAP2 Pipeline Example\n",
    "This document aims to demonstrate the SLAP2 pipelines highlighted in the paper. The SLAP2_Util library requires the installation of mandatory libraries, including CUPY, which relies on an NVIDIA GPU. Thus, it is highly recommended that the code be run on a computer with a GPU.\n",
    "The overall pipeline is outlined in the following code block, where the data of each region of interest (ROI) is extracted and organized based on their index. The document will highlight each steps as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0958562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.draw import polygon_perimeter\n",
    "from Desktop.SLAP2_Utils.slap2_utils.datafile import DataFile\n",
    "from Desktop.SLAP2_Utils.slap2_utils.subclasses.metadata import MetaData\n",
    "from Desktop.SLAP2_Utils.slap2_utils.utils.trace import Trace\n",
    "from Desktop.SLAP2_Utils.slap2_utils.utils.roi_utils import roiBoolean, roiImg\n",
    "\n",
    "hDataFile = DataFile('C://Users//Jerry//Desktop//testFile.dat');\n",
    "\n",
    "raw_data = []\n",
    "processed_data = []\n",
    "print(\"Loading passed. Data extraction will start now.\")\n",
    "\n",
    "for _roi in range(len(hDataFile.metaData.AcquisitionContainer.ROIs)):\n",
    "    roi_shape = hDataFile.metaData.AcquisitionContainer.ROIs[_roi].shapeData\n",
    "    ROI = hDataFile.metaData.AcquisitionContainer.ROIs[_roi]\n",
    "    zIdx = hDataFile.fastZs.index(ROI.z)\n",
    "    chIdx = 1\n",
    "    hTrace = Trace(hDataFile, zIdx, chIdx)\n",
    "\n",
    "    roi_shape = roi_shape.astype(int)\n",
    "    integrationPixels = roiBoolean(hDataFile, _roi)\n",
    "\n",
    "    rasterPixels = np.full((800, 1280), False)\n",
    "    hTrace.setPixelIdxs(rasterPixels, integrationPixels);\n",
    "    individual_processed_trace, _, _, _ = hTrace.process(10, 1000)\n",
    "    processed_data.append(individual_processed_trace)\n",
    "    hTrace.orderadjust()\n",
    "    individual_raw = []\n",
    "    for x in range(len(hTrace.TracePixels)):\n",
    "        individual_raw.append(hTrace.TracePixels[x].data[0][:400])\n",
    "    raw_data.append(individual_raw)\n",
    "\n",
    "\n",
    "print('Completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35a6c9",
   "metadata": {},
   "source": [
    "Once the files are outputted from SLAP2, the DataFile object will be produced first. This object loads the binary files into the Python environment. When successful, the function will output \"DataFile Created,\" which also indicates that the function has ended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f1eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hDataFile = DataFile('C://Users//Jerry//Desktop//testFile.dat');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75acdce",
   "metadata": {},
   "source": [
    "If the user wish to view the ROI's shape in a 2D plane, the user will need to load the ROI shape from each ROI. The information can be extracted from skimage using the `polygon_perimeter` function or with roi_util functions. The `polygon_perimeter` function can only accept list with size larger than 2 such that it is actually a polygon, so extra loop must be implemented to account for this exception. The function utilizes matplotlib to show the image after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80246d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img2 = np.zeros((800, 1280), dtype=np.uint32)\n",
    "\n",
    "for _roi in range(len(hDataFile.metaData.AcquisitionContainer.ROIs)):\n",
    "    roi_shape = hDataFile.metaData.AcquisitionContainer.ROIs[_roi].shapeData\n",
    "    if roi_shape.shape[0] == 2:\n",
    "        if len(roi_shape[0,:]) > 2 :\n",
    "            rr, cc = polygon_perimeter(roi_shape[0, :], roi_shape[1, :],\n",
    "            shape=img2.shape, clip=True)\n",
    "            img2[rr, cc] = _roi + 1\n",
    "        else:\n",
    "            rr = []\n",
    "            cc = []\n",
    "            for i in roi_shape[0, :]:\n",
    "                for j in roi_shape[1, :]:\n",
    "                    rr.append(int(i))\n",
    "                    cc.append(int(j))\n",
    "            img2[rr, cc] = _roi + 1\n",
    "\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8567523",
   "metadata": {},
   "source": [
    "If the user wish to know the ROI shape of a specific ROI (and the index that corresponds to it), user can use the `roiImg` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294835cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If one wants to see ROI at the first index (0)\n",
    "plt.plot(roiImg(hDataFile,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf81522",
   "metadata": {},
   "source": [
    "For the data to be extracted, the user must input a boolean array that indicates where the pixels are for specific ROIs. The channel index (chIdx) can be changed or extracted from the file. `Trace` is called, and the function `setPixelIdxs` is then called with the boolean array inputted. The `process` function loads the data into the object and outputs a convolved trace as `individual_processed_trace`. This trace is the trace result of the whole ROI, which is a summation of each individual superpixel inside a specific ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe13b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "print(\"Extracting processed trace...\")\n",
    "\n",
    "for _roi in range(len(hDataFile.metaData.AcquisitionContainer.ROIs)):\n",
    "    roi_shape = hDataFile.metaData.AcquisitionContainer.ROIs[_roi].shapeData\n",
    "    ROI = hDataFile.metaData.AcquisitionContainer.ROIs[_roi]\n",
    "    zIdx = hDataFile.fastZs.index(ROI.z)\n",
    "    chIdx = 1\n",
    "    hTrace = Trace(hDataFile, zIdx, chIdx)\n",
    "\n",
    "    roi_shape = roi_shape.astype(int)\n",
    "    integrationPixels = roiBoolean(hDataFile, _roi)\n",
    "\n",
    "    rasterPixels = np.full((800, 1280), False)\n",
    "    hTrace.setPixelIdxs(rasterPixels, integrationPixels)\n",
    "    \n",
    "    individual_processed_trace, _, _, _ = hTrace.process(10, 1000)\n",
    "    processed_data.append(individual_processed_trace)\n",
    "\n",
    "print(\"Extraction completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae621dc3",
   "metadata": {},
   "source": [
    "If the user wishes to extract the raw data inside the superpixels of the trace object (that also represents one ROI), the raw data is inside the `TracePixel` field. The function `orderadjust` must be called in this case because reordering in processed trace extraction is not necessary when it is outputting a sum of all superpixels. The example below extracts data of a specific range (the first superpixel, from 0 to the 400th acquisition), but the number is modifiable if the user wishes to sample a different range of data. The list here will include data from all the loops in the acquisition plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e2cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "print(\"Extracting raw data...\")\n",
    "\n",
    "for _roi in range(len(hDataFile.metaData.AcquisitionContainer.ROIs)):\n",
    "    roi_shape = hDataFile.metaData.AcquisitionContainer.ROIs[_roi].shapeData\n",
    "    ROI = hDataFile.metaData.AcquisitionContainer.ROIs[_roi]\n",
    "    zIdx = hDataFile.fastZs.index(ROI.z)\n",
    "    chIdx = 1\n",
    "    hTrace = Trace(hDataFile, zIdx, chIdx)\n",
    "\n",
    "    roi_shape = roi_shape.astype(int)\n",
    "    integrationPixels = roiBoolean(hDataFile, _roi)\n",
    "\n",
    "    rasterPixels = np.full((800, 1280), False)\n",
    "    hTrace.setPixelIdxs(rasterPixels, integrationPixels);\n",
    "    hTrace.orderadjust()\n",
    "\n",
    "    individual_processed_trace, _, _, _ = hTrace.process(10, 1000)\n",
    "    processed_data.append(individual_processed_trace)\n",
    "    hTrace.orderadjust()\n",
    "    individual_raw = []\n",
    "    for x in range(len(hTrace.TracePixels)):\n",
    "        individual_raw.append(hTrace.TracePixels[x].data[0][:400])\n",
    "    raw_data.append(individual_raw)\n",
    "\n",
    "print(\"Extraction completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ecbca",
   "metadata": {},
   "source": [
    "The user can view the data through matplotlib (example below shows a plot of a raw and processed data at the first acquisition loop). Other libraries would work as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e914ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_plot = plt.plot(processed_data[0])\n",
    "plt.show()\n",
    "raw_data_plot = plt.plot(raw_data[0][0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
